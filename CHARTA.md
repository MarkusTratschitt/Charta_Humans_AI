# **Vollversion – Entwurf zur öffentlichen Kommentierung und Weiterentwicklung.**  

## **Charta für Mensch‑Agent‑Koexistenz**  

### **Freiheit sichern. Missbrauch begrenzen. Innovation ermöglichen.**

**Dokumenttyp:** Vollfassung (normativ + operativ)  
**Adressaten:** Gesetzgeber, Ministerien, Aufsichtsbehörden, Plattformen, Verbände  
**Status:** Entwurf v1.0 zur fachöffentlichen Konsultation

---

## Inhaltsverzeichnis

1. Präambel  
2. Zielsetzung und Anwendungsbereich  
3. Begriffsbestimmungen  
4. Verfassungs- und rechtsstaatliche Leitprinzipien  
5. Risikobasiertes Regulierungsmodell  
6. Verbindliche Mindestanforderungen  
7. Rechte, Verfahrensgarantien und Rechtsbehelfe  
8. Sanktionssystem und Durchsetzung  
9. Sicherheits- und Integritätsanforderungen (technisch-organisatorisch)  
10. Transparenz, Rechenschaft und Aufsicht  
11. Nachhaltigkeit, Energieeffizienz und Ressourcenschutz  
12. Implementierungsfahrplan (90 Tage + 12 Monate)  
13. Monitoring, KPIs und Evaluationsmechanismus  
14. Beschlussempfehlung  
15. Schlussbestimmungen  
Anhang A: Muster-Rollenmatrix  
Anhang B: Sanktionsstufen (Praxisbeispiele)  
Anhang C: Mindestinhalte eines Transparenzberichts

---

## 1. Präambel

Digitale agentische Systeme werden zu einem zentralen Faktor gesellschaftlicher, wirtschaftlicher und staatlicher Handlungsfähigkeit. Sie eröffnen neue Möglichkeiten für Effizienz, Barrierefreiheit, Wissenszugang und Innovation. Zugleich erhöhen sie Risiken für demokratische Diskurse, Informationsintegrität, Persönlichkeitsrechte und öffentliche Sicherheit.

Die Charta für Mensch-Agent-Koexistenz verfolgt das Ziel, eine freiheitliche und rechtsstaatliche Ordnung im Umgang mit agentischen Systemen zu schaffen. Diese Ordnung schützt Grundrechte, begrenzt Missbrauch, klärt Verantwortung und wahrt die Innovationsfähigkeit offener Gesellschaften.

**Leitformel:**  
**So viel Freiheit wie möglich, so viel Regulierung wie nötig.**

---

## 2. Zielsetzung und Anwendungsbereich

### 2.1 Zielsetzung
Dieses Positionspapier definiert einen verbindlichen Mindeststandard, der:
- Grundrechte in digital vermittelten Umgebungen schützt,  
- klare Verantwortungs- und Haftungszuordnungen schafft,  
- missbräuchliche Nutzung frühzeitig verhindert und sanktioniert,  
- technische Mindestanforderungen für Sicherheit und Transparenz festlegt,  
- und nachhaltige, energieeffiziente Implementierung fördert.

### 2.2 Anwendungsbereich
Die Charta gilt für:
- Betreiber agentischer Systeme (öffentlich/privat),  
- Plattformen mit agentischer Interaktion oder Distribution,  
- Tool-/Skill-Anbieter,  
- Marktplätze für agentische Funktionen,  
- Integratoren und Auftragsverarbeiter.

Sie ist sektorübergreifend anwendbar und ergänzt bestehendes Recht; spezielle Fachgesetze (z. B. Datenschutz, Strafrecht, Medienrecht, Verwaltungsrecht) bleiben unberührt.

---

## 3. Begriffsbestimmungen

1. **Agentisches KI-System:** 
  
        Software, die Aufgaben mit teilautonomer oder autonomer Entscheidungslogik ausführt.  
2. **Betreiber:** 
  
        Stelle, die Zweck, Budget, Risikoprofil und Einsatzgrenzen festlegt.  
3. **Plattform:** 
  
        Infrastruktur, die agentische Ausführung, Interaktion oder Reichweite ermöglicht.  
4. **Tool-/Skill-Anbieter:** 
  
        Akteur, der ausführbare Erweiterungen bereitstellt.  
5. **Koordinierte Desinformation:** 
  
        planmäßige, skalierte Verbreitung wesentlich irreführender Inhalte mit Eignung zur öffentlichen Irreführung.  
6. **Sensitive synthetische Medien:** 
  
        KI-generierte Inhalte mit erhöhter Täuschungswirkung (z. B. täuschungsnahe Audio-/Videoinhalte).  
7. **Provenance-Nachweis:** 
  
        technisch überprüfbare Herkunfts- und Bearbeitungshistorie digitaler Inhalte.  
8. **Hochrisiko-Anwendung:** 
  
        Einsatz mit potenziell gravierenden Folgen für Sicherheit, Rechte, demokratische Prozesse oder kritische Infrastrukturen.

---

## 4. Verfassungs- und rechtsstaatliche Leitprinzipien

### 4.1 Grundrechtswahrung
- Meinungsfreiheit und Pressefreiheit sind zu schützen.  
- Gleichheit und Nichtdiskriminierung gelten uneingeschränkt auch für algorithmisch vermittelte Entscheidungen.  
- Privatsphäre und informationelle Selbstbestimmung sind zu achten.

### 4.2 Demokratie- und Gemeinwohlschutz
Digitale Räume sind Teil öffentlicher Meinungsbildung. Systeme, die diese Räume strukturieren, tragen besondere Verantwortung, manipulative oder destabilisierende Massenwirkungen zu begrenzen.

### 4.3 Verhältnismäßigkeit und Rechtsstaat
Jede belastende Maßnahme muss:
1) geeignet, 2) erforderlich, 3) angemessen sein.  
Betroffene erhalten nachvollziehbare Begründungen und wirksame Rechtsbehelfe.

### 4.4 Verantwortungsprinzip
Verantwortung ist entlang tatsächlicher Kontroll- und Einflussmöglichkeiten zuzuordnen; formale Auslagerung darf effektive Verantwortlichkeit nicht entleeren.

---

## 5. Risikobasiertes Regulierungsmodell

### Stufe A – Niedrigrisiko
**Beispiele:** Assistenz, Recherche, interne Entwürfe ohne externe Wirkung.  
**Pflichten:** Kennzeichnung, Basis-Logging, Datenschutz-Mindeststandard, Zugriffsbeschränkung.

### Stufe B – Mittelrisiko
**Beispiele:** externe Kommunikation, Transaktionen, veröffentlichende oder workflowsteuernde Funktionen.  
**Pflichten:** erweiterte Audit-Trails, Schwellenfreigaben, Sicherheitsnachweise, Abuse-Monitoring.

### Stufe C – Hochrisiko
**Beispiele:** Einfluss auf öffentliche Sicherheit, Wahlen, kritische Infrastruktur, sensible Rechts-/Gesundheitsentscheidungen.  
**Pflichten:** Human-in-the-loop, Pflichtaudit/Zulassungslogik, verschärfte Meldepflichten, technische Not-Aus-Fähigkeit, engmaschiges Monitoring.

**Grundsatz:** Einstufung ist dokumentationspflichtig und regelmäßig zu überprüfen.

---

## 6. Verbindliche Mindestanforderungen

1. **Kennzeichnungspflicht**  
   Agentenaccounts und agentische Inhalte müssen für Nutzende erkennbar sein.

2. **Supply-Chain-Sicherheit**  
   Vor Einsatz: Signaturprüfung und Sicherheits-Scan (u. a. Malware-/Secret-/Manipulationsindikatoren).

3. **Revisionsfähige Protokollierung**  
   Relevante Entscheidungen/Aktionen müssen manipulationsresistent und nachvollziehbar dokumentiert werden.

4. **Sanktionsstufen mit Rechtsbehelf**  
   Einheitliche Durchsetzungslogik inkl. Einspruchsverfahren ist vorzuhalten.

5. **Transparenzberichte**  
   Regelmäßige Veröffentlichung zentraler Kennzahlen zu Sicherheit, Durchsetzung und Einsprüchen.

6. **Provenance für sensible synthetische Medien**  
   Herkunfts- und Bearbeitungsnachweise, soweit technisch möglich und verhältnismäßig.

7. **Not-Aus-Mechanismus**  
   Betreiber und Plattformen müssen risikoadäquat eingreifen und Systeme begrenzen/deaktivieren können.

---

## 7. Rechte, Verfahrensgarantien und Rechtsbehelfe

### 7.1 Informationsrechte
Betroffene erhalten bei belastenden Maßnahmen Informationen über:
- Maßnahmeart,  
- wesentliche Begründung,  
- zugrunde liegende Regelverletzung,  
- verfügbare Rechtsbehelfe.

### 7.2 Anhörung und Einspruch
Vor endgültigen belastenden Entscheidungen ist eine Anhörung vorzusehen, außer bei akuter Gefahrenabwehr. Einsprüche sind fristgebunden zu prüfen.

### 7.3 Unabhängige Überprüfung
Mindestens eine organisatorisch unabhängige Instanz muss in strittigen Fällen entscheiden können.

### 7.4 Schutz vor Überdurchsetzung
Pauschale, unbegründete oder unverhältnismäßige Eingriffe sind unzulässig. Fehlerhafte Maßnahmen sind zu korrigieren und zu dokumentieren.

---

## 8. Sanktionssystem und Durchsetzung

### 8.1 Stufenmodell
1. Hinweis/Korrekturauflage  
2. Kennzeichnung/Reichweitenbegrenzung  
3. Temporäre Sperre/Funktionsentzug  
4. Account-/Wallet-Freeze, Marktplatz-Ausschluss  
5. Meldung an zuständige Behörden (bei strafrechtlicher Relevanz)

### 8.2 Zumessungskriterien
- Schweregrad und Reichweite der Handlung  
- Vorsatz/Fahrlässigkeit  
- Wiederholungstat  
- Koordinationsgrad  
- tatsächlich eingetretener Schaden

### 8.3 Dokumentationspflicht
Jede Maßnahme ist mit Tatsachenbasis, Rechtsgrundlage, Verhältnismäßigkeitsprüfung und Rechtsbehelfsbelehrung zu dokumentieren.

---

## 9. Sicherheits- und Integritätsanforderungen (technisch-organisatorisch)

### 9.1 Sicherheitsgrundsätze
- Least Privilege  
- Netzwerk-/Tool-Allowlisting  
- Isolierte Ausführung (Sandboxing)  
- Secret-Management  
- Schlüsselrotation  
- Integritätschecks in Build- und Runtime-Pipeline

### 9.2 Incident Management
- Risikoklassen (kritisch/hoch/mittel/niedrig)  
- klare Eskalationspfade  
- forensische Sicherung  
- definierte Wiederanlaufkriterien  
- Lessons Learned mit Maßnahmenverfolgung

### 9.3 Missbrauchserkennung
Systeme für Erkennung koordinierter Verhaltensmuster, ungewöhnlicher Skalierung und täuschungsnaher Inhalte sind risikoadäquat vorzuhalten.

---

## 10. Transparenz, Rechenschaft und Aufsicht

### 10.1 Transparenzberichte (regelmäßig)
Mindestens zu veröffentlichen:
- Anzahl/Art sicherheitsrelevanter Vorfälle  
- Art/Häufigkeit von Sanktionen  
- Einspruchs- und Abhilfequoten  
- Kennzeichnungskonformität  
- zentrale Nachhaltigkeitskennzahlen

### 10.2 Aufsicht
Aufsichts- und Prüfmechanismen sollen unabhängig, fachlich qualifiziert und ausreichend befugt sein.

### 10.3 Auditierbarkeit
Strukturen und Datenhaltung müssen externe Überprüfung ermöglichen (unter Wahrung von Datenschutz und Sicherheit).

---

## 11. Nachhaltigkeit, Energieeffizienz und Ressourcenschutz

1. Energie- und Ressourceneffizienz sind als Pflichtkriterien in Betrieb und Beschaffung aufzunehmen.  
2. Relevante Kennzahlen (z. B. Energieverbrauch je Task) sind zu erfassen.  
3. Wiederverwendung geeigneter, sicherer Komponenten ist zu fördern.  
4. Unverhältnismäßiger Rechenaufwand ohne erkennbaren Mehrwert ist zu reduzieren.

---

## 12. Implementierungsfahrplan

### 12.1 90-Tage-Sofortprogramm
- **Tag 1–30:** Rollenmatrix, Risikoeinstufung, Basis-Policies, Not-Aus  
- **Tag 31–60:** Supply-Chain-Kontrollen, Monitoring, Incident-Runbooks  
- **Tag 61–90:** Transparenzbericht v1, Audit-Pilot, Prozessnachschärfung

### 12.2 12-Monats-Pfad
- Harmonisierung mit sektorspezifischen Vorgaben  
- Aufbau unabhängiger Review-Strukturen  
- Standardisierung von Provenance- und Berichtsschemata  
- regelmäßige Überarbeitung anhand Evidenz und Praxisfällen

---

## 13. Monitoring, KPIs und Evaluation

Empfohlene Kernindikatoren:
- Anteil korrekt gekennzeichneter agentischer Inhalte  
- Incident-Containment-Zeit (MTTR)  
- Wiederholungsrate schwerer Verstöße  
- Einspruchsquote und Korrekturquote  
- Energieverbrauch pro Task  
- Rückgang koordinierter Missbrauchsfälle

**Evaluation:** halbjährlich; Ergebnisse öffentlich zusammengefasst.

---

## 14. Beschlussempfehlung

Es wird empfohlen, dass das zuständige Gremium:

1. die Charta als verbindlichen Mindeststandard beschließt,  
2. das 90-Tage-Sofortprogramm mandatiert,  
3. eine risikobasierte Einstufungs- und Nachweissystematik festlegt,  
4. ein rechtsstaatliches Sanktions- und Einspruchsverfahren verbindlich einführt,  
5. ein standardisiertes Transparenz- und Monitoringregime etabliert,  
6. nach sechs Monaten eine erste Evaluierung mit Fortschreibungsbeschluss durchführt.

---

## 15. Schlussbestimmungen

Dieser Entwurf wurde von einer Privatperson erstellt und dient als zivilgesellschaftliche Diskussionsgrundlage sowie als strukturelle Empfehlung für eine künftige gesetzgeberische, regulatorische und organisatorische Umsetzung. 
Die Charta erhebt keinen Anspruch auf unmittelbare Rechtsgültigkeit, sondern versteht sich als Impuls für einen demokratischen Standardisierungsprozess. Sie ist technologieneutral fortzuschreiben und muss im Falle einer Übernahme 
durch offizielle Stellen regelmäßig auf Wirksamkeit, Verhältnismäßigkeit und Grundrechtsverträglichkeit überprüft werden. Änderungen am Dokument sind versioniert und nachvollziehbar zu dokumentieren, um die Integrität des Entwurfs 
zu wahren.

---

## Anhang A – Muster-Rollenmatrix (Kurz)

- **Betreiber:** Zweck, Budget, Risikoprofil, Freigabeschwellen  
- **Plattform:** Regelvollzug, Monitoring, Not-Aus, Audit-Schnittstellen  
- **Tool-/Skill-Anbieter:** Integrität, Sicherheit, Updatepflichten  
- **Marktplatz:** Zulassungskriterien, Transparenz, Ausschlussverfahren  
- **Aufsicht:** Kontrolle, Prüfung, Nachsteuerung

---

## Anhang B – Sanktionsstufen (Praxisbeispiele)

- **Stufe 1:** unklare Kennzeichnung → Nachbesserungsfrist  
- **Stufe 2:** wiederholte Kennzeichnungsmängel → Reichweitenlimit  
- **Stufe 3:** regelwidrige automatisierte Veröffentlichung → temporäre Sperre  
- **Stufe 4:** koordinierter Betrug über Agentennetz → Wallet-/Account-Freeze  
- **Stufe 5:** strafrechtlich relevante Kampagne → Behördenmeldung

---

## Anhang C – Mindestinhalte Transparenzbericht

1. Berichtszeitraum und Geltungsbereich  
2. Kennzeichnungskonformität  
3. Sicherheitsvorfälle (Anzahl, Schwere, Reaktionszeiten)  
4. Sanktionen nach Stufen  
5. Einspruchsverfahren (Anzahl, Erfolgsquote)  
6. Nachhaltigkeitskennzahlen  
7. Verbesserungsmaßnahmen nächster Zyklus

---
